#!/usr/bin/env python3
import argparse
import csv
import github
import jinja2
import os
import re
import requests
import yaml


def get_packages():
    packages = []

    with open(os.path.join("data", "packages.csv")) as f:
        reader = csv.DictReader(f)
        for row in reader:
            recipe_name = row["repository"].split("github.com/")[1]
            recipe_path = os.path.join("packages", recipe_name + ".yml")
            if not os.path.isfile(recipe_path):
                recipe_name = ""
                recipe_path = ""

            packages.append(
                {
                    "repository": {
                        "name": row["repository"].split("github.com/")[1],
                        "url": row["repository"],
                    },
                    "default_branch": row["default_branch"],
                    "latest_release": row["latest_release"],
                    "recipe": {
                        "name": recipe_name,
                        "path": recipe_path,
                    },
                }
            )

    packages = sorted(packages, key=lambda x: x["repository"]["name"])

    return packages


def update_packages():
    GITHUB_ACCESS_TOKEN = os.environ.get("GITHUB_ACCESS_TOKEN", "")

    client = github.Github(GITHUB_ACCESS_TOKEN)

    data = []

    for repo in client.get_organization("elementary").get_repos():
        if repo.archived:
            continue

        latest_release = None
        try:
            latest_release = repo.get_latest_release().tag_name
        except:
            pass

        print(repo.html_url, repo.default_branch, latest_release)

        data.append({
            "repository": repo.html_url,
            "default_branch": repo.default_branch,
            "latest_release": latest_release,
        })

    data = sorted(data, key=lambda x: x["repository"])

    with open(os.path.join("data", "packages.csv"), "w", newline="") as csvfile:
        fieldnames = ["repository", "default_branch", "latest_release"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        for row in data:
            writer.writerow(row)


def update_readme(packages):
    context = {
        "packages": packages,
    }

    template_text = open(os.path.join("data", "README.md.jinja2"), "r").read()
    template = jinja2.Template(template_text)
    text = template.render(context)

    f = open("README.md", "w")
    f.write(text)


def get_build_dependencies(package_name):
    url = f"https://raw.githubusercontent.com/{package_name}/deb-packaging/debian/control"

    r = requests.get(url)

    if r.status_code != 200:
        return []

    data = r.text

    # Find the Build-Depends line
    pattern = r'Build-Depends:\s*((?:\s*(?:#.*|[^#\n]+)\n)+?)(?=\n\S|$)'
    match = re.search(pattern, data)

    if not match:
        return []

    # Extract the captured group, which is the content of the Build-Depends block
    build_depends_content = match.group(1).strip()
    # Split the content into lines and filter out any lines that start with a non-whitespace character
    filtered_lines = [line for line in build_depends_content.split('\n') if line.startswith(' ') or line.startswith('#') or line.startswith('appstream')]

    for line in data.split('\n'):
        if line.startswith('Build-Depends:'):
            l = line.split("Build-Depends:")[1].strip()
            for d in l.split(','):
                d = d.strip()
                if d not in filtered_lines:
                    filtered_lines.append(d)
            break

    # Remove comments and split the dependencies
    dep_list = []
    for line in filtered_lines:
        # Remove comments
        line = re.sub(r'#.*$', '', line).strip()
        if line:
            # Split by comma, but keep empty items for lines ending with ','
            deps = [dep.strip() for dep in line.split(',')]
            dep_list.extend(deps)

    # Remove empty items and extract package names
    dep_list = [dep.split()[0] for dep in dep_list if dep]

    excludes = [
        "debhelper",
        "debhelper-compat",
        "dh-exec",
        "dh-sequence-gir",
    ]

    for exclude in excludes:
        if exclude in dep_list:
            dep_list.remove(exclude)

    dep_list = list(set(dep_list))

    dep_list.sort()

    return dep_list


def get_build_options(package_name):
    url = f"https://raw.githubusercontent.com/{package_name}/deb-packaging/debian/rules"

    r = requests.get(url)

    if r.status_code != 200:
        return {}

    data = r.text

    build_options = {}

    for line in data.split("\n"):
        line = line.strip()

        if not line.startswith("dh_auto_configure"):
            continue

        for part in line.split(" "):
            if part.strip().startswith("-D") and "=" in part:
                option = part.strip().split("=")[0][2:]
                value = part.strip().split("=")[1]

                if value.lower() in ["true", "false"]:
                    value = value.lower() == "true"

                build_options[option] = value

    return build_options


def update_recipes(packages):
    packages_recipes_dir = os.path.abspath("packages")

    class Dumper(yaml.Dumper):
        def increase_indent(self, flow=False, *args, **kwargs):
            return super().increase_indent(flow=flow, indentless=False)

    for dirpath, dirnames, filenames in os.walk(packages_recipes_dir):
        for file in filenames:
            path = os.path.join(dirpath, file)

            with open(path, "r") as rf:
                package = yaml.safe_load(rf)

                for p in packages:
                    if package["name"] == p["repository"]["name"]:
                        build_package = {
                            "name": p["repository"]["name"],
                            "buildsystem": "meson",
                            "build-options": get_build_options(p["repository"]["name"]),
                            "dependencies": get_build_dependencies(p["repository"]["name"]),
                            "sources": [
                                {
                                    "type": "git",
                                    "url": p["repository"]["url"],
                                    "tag": p["default_branch"],
                                },
                            ]
                        }

                        if build_package["build-options"] == {}:
                            del build_package["build-options"]

                        with open(path, "w") as wf:
                            yaml.dump(build_package, wf, Dumper=Dumper, sort_keys=False)


def update_workflows(packages):
    context = {
        "packages": [],
    }

    for package in packages:
        recipe_name = package.get("recipe", {}).get("name", None)
        if not recipe_name:
            continue

        context["packages"].append(recipe_name)

    context["packages"].sort()

    template_dir = os.path.join("data", ".github", "workflows")
    for filename in os.listdir(template_dir):
        path = os.path.join(template_dir, filename)
        if not os.path.isfile(path):
            continue

        template_text = open(path, "r").read()
        template = jinja2.Template(template_text)
        text = template.render(context)

        f = open(path.split("data/")[-1].replace(".jinja2", ""), "w")
        f.write(text)


def main(args):
    if args.packages:
        update_packages()

    if args.readme:
        update_readme(get_packages())

    if args.workflows:
        update_workflows(get_packages())

    if args.recipes:
        update_recipes(get_packages())

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--packages", action="store_true")
    parser.add_argument("--readme", action="store_true")
    parser.add_argument("--workflows", action="store_true")
    parser.add_argument("--recipes", action="store_true")

    main(parser.parse_args())
